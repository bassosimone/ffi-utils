# Measurement Kit FFI API

Measurement Kit exposes a simple C like API suitable to be used via
[FFI](https://en.wikipedia.org/wiki/Foreign_function_interface).

As of MK v0.9.0, this API is still experimental. You should probably not
use this API directly, rather you should use the high level wrappers that
we have implemented for several languages. Specifically:

- for Android and Java you should use our [Java API](
  https://github.com/measurement-kit/android-libs);

- for Golang you should use our [Golang API](
  https://github.com/measurement-kit/go-measurement-kit);

- for C++11 and better, and Objective C, you should use our
  [C++11 API](../nettest/nettest.hpp).

## Introduction and synopsis

Measurement Kit is a network measurement engine. By default, as mentioned,
it exposes a FFI friendly C like API. To use this API, include
`<measurement_kit/ffi.h>`. See also the API documentation available
at [codedocs.xyz/measurement-kit/measurement-kit](
https://codedocs.xyz/measurement-kit/measurement-kit).

The FFI API allows you to run _tasks_. In most cases tasks are network
measurement tests, like [OONI's Web Connectivity](
https://github.com/ooni/spec/blob/master/test-specs/ts-017-web-connectivity.md
) or the [Network Diagnostic Test](
https://github.com/ooni/spec/blob/master/test-specs/ts-022-ndt.md).

To _start_ a task you call `mk_task_start` by passing it specific
_settings_ as a serialized JSON string.  All settings are optional,
except for the `name` of the task.  Ideally, you should have high
level code where the settings are a class that gets serialized to
a JSON string. This is, for example, what we do in the higher-level
[C++14 API](cxx14.hpp).

Once started, a task will emit _events_. There are several kind of
events, the most common of which is `"log"` that identifies a log
line emitted by the task. Another event is `"status.update.performance"`,
which provides network performance information while a task for
measuring network performance is being run. See below for more
information on the specific events.

The task runs in a separate thread and posts events on a queue. You extract
events from such queue using `mk_task_wait_for_next_event`. This is a _blocking_
function that returns when a new event is posted into the queue. To
process an event, use `mk_event_serialize` to obtain its JSON serialization,
then parse the JSON into some high level data structure, and process it. See,
again, the [C++14 API](cxx14.hpp) events processing code to have an idea of
how this could be implemented. (Or, if we have already written an API that
does that works for your use case, perhaps just use such API.)

You should loop processing events until `mk_task_is_done` returns nonzero. At
that point, the task is done, and attempting to extract further events from
the queue with `mk_task_wait_for_next_event` will immediately return the dummy
`status.terminated` event (equivalent to `EOF` for the task queue).

Since the FFI API is basically a C API, you need to manually manage memory
by freeing events and the task, once you are done with them. To this end, use
respectively, `mk_event_destroy` and `mk_task_destroy`.

## Examples

You can find working examples of usage of the FFI API inside the
[example/ffi](../../example/ffi) directory. Another usage example of
the FFI API is [cxx14.hpp](cxx14.hpp). In such file, we wrap the FFI API
into a more-user-friendly C++14 interface, by mapping each event to
a class. Specifically, it may be of interest to read how we
process events in the `run()` and `process_event()` functions.

## Tasks

The following tasks are defined (case matters):

{% for nettest in nettests %}
- `"{{ nettest.key.to_pascal_case() }}"`: [{{ nettest.docs }}](
  {{ nettest.reference_url }}).
{% endfor %}

By following the links provided above, you can read detailed documentation on
the purpose of each task. The documentation also describes the JSON schema used
by each task to represent its results. As mentioned below, tasks results are
emitted as a serialized JSON under the `"measurement"` event.

## Settings

The task settings is a JSON like:

```JSON
{
  "annotations": {
    "an_annotation": "with its value",
    "another_annotation": "with its specific value"
  },
  "disabled_events": [
    "status.queued",
    "status.started"
  ],
  "inputs": [
    "www.google.com",
    "www.x.org"
  ],
  "input_filepaths": [
    "/path/to/file",
    "/path/to/another/file"
  ],
  "log_filepath": "logfile.txt",
  "log_level": "INFO",
  "name": "WebConnectivity",
  "options": {
    "bouncer_base_url": "",
    "collector_base_url": "",
    "dns/nameserver": "",
    "dns/engine": "system",
    "geoip_asn_path": "",
    "geoip_country_path": "",
    "ignore_bouncer_error": 1,
    "ignore_open_report_error": 1,
    "max_runtime": -1.0,
    "net/ca_bundle_path": "",
    "net/timeout": 10.0,
    "no_bouncer": 0,
    "no_collector": 0,
    "no_asn_lookup": 0,
    "no_cc_lookup": 0,
    "no_ip_lookup": 0,
    "no_file_report": 0,
    "no_resolver_lookup": 0,
    "probe_asn": "",
    "probe_cc": "",
    "probe_ip": "",
    "randomize_input": 1,
    "save_real_probe_asn": 1,
    "save_real_probe_cc": 1,
    "save_real_probe_ip": 0,
    "save_real_resolver_ip": 1,
    "software_name": "measurement_kit",
    "software_version": "<current-mk-version>"
  },
  "output_filepath": "results.njson"
}
```

The only mandatory key is `name`, which identifies the task. All the other
keys are optional. Above we have shown the most commonly used `options`, that
are described in greater detail below. The value we included for options
is their default value (_however_, the value of non-`options` settings _is not_
the default value, rather is a meaningful example). The following keys
are available:

{% for setting in settings %}
- `"{{ setting.key }}"`: ({{ setting.base_type.decl("docs") }}) {{ setting.docs }}
{% endfor %}

## Log levels

The available log levels are:

{% for log_level in log_levels %}
- `"{{ log_level.key.to_snake_case_upper() }}"`: {{ log_level.docs }}
{% endfor %}

When you specify a log level in the settings, only messages with a log level
equal or greater than the specified one are emitted. For example, if you
specify `"INFO"`, you will only see `"ERR"`, `"WARNING"`, and `"INFO"` logs.

## Options

Options can be `string`, `float`, or `int`. There is not boolean type, and
we use `int`s with boolean semantics in some cases, with the usual convention
that `0` means false and non-`0` means true.

These are the available options:

{% for option in options %}
- `"{{ option.key }}"`: ({{ option.base_type.decl("docs") }}) {{ option.docs }}
{% endfor %}

## Events

An event is a JSON object like:

```JSON
  {
    "key": "<key>",
    "value": {}
  }
```

Where `"value"` is a JSON object with an event-specific structure, and `"key"`
is a string. Below we describe all the possible event keys, along with the
"value" JSON structure. Unless otherwise specified, an event key can be emitted
an arbitrary number of times during the lifecycle of a task. Unless otherwise
specified, all the keys introduced below where added in MK v0.9.0.

The following events are defined:

{%for event in events %}
- `"{{ event.key }}"`: (object) [documentation](#{{ event.key|replace(".", "") }})
{% endfor %}

Below we provide a detailed description of each event.

{%for event in events %}
### {{ event.key }}

{{ event.docs }}

{% if event.attributes|length > 0 %}This event includes the following attributes:
{% for attribute in event.attributes %}
1. `"{{ attribute.key }}"`: ({{ attribute.base_type.decl("docs") }}) {{ attribute.docs }}{% endfor %}{% endif %}

The JSON returned by this event is like:

```JSON
{
  "key": "{{ event.key }}",
  "value": { {% for attribute in event.attributes %} {{ "\n   " if loop.first }} "{{ attribute.key }}": {{ attribute.base_type.default_value("docs") }}{{ ",\n  " if not loop.last }}{% endfor %}
  }
}
```
{% endfor %}

## Task pseudocode

The following illustrates in pseudocode the operations performed by a task
once you call `mk_task_start`. It not 100% accurate; in particular, we have
omitted the code that generates most log messages. This pseudocode is meant to
help you understand how Measurement Kit works internally, and specifically how all
the settings described above interact together when you specify them for
running Measurement Kit tasks. We are using pseudo JavaScript because that
is the easiest language to show manipulation of JSON objects such as the
`settings` object.

As mentioned, a task run in its own thread. It first validate settings, then
it opens the logfile (if needed), and finally it waits in queue until other
possibly running tasks terminate. The `finish` function will be called when the
task is done, and will emit all the events emitted at the end of a task.

```JavaScript
function taskThread(settings) {
  emitEvent("status.queued", {})
  semaphore.Acquire()                 // blocked until my turn

  let finish = function(error) {
    semaphore.Release()               // allow another test to run
    emitEvent("status.end", {
      downloaded_kb: countDownloadedKb(),
      uploaded_kb: countUploadedKb(),
      failure: (error) ? error.AsString() : null
    })
  }

  if (!settingsAreValid(settings)) {
    emitEvent("failure.startup", {
      failure: "value_error",
    })
    finish("value_error")
    return
  }

  if (settings.log_filepath != "") {
    // TODO(bassosimone): we should decide whether we want to deal with the
    // case where we cannot write into the log file. Currently we don't.
    openLogFile(settings.log_filepath)
  }

  let task = makeTask(settings.name)

  emitEvent("status.started", {})


```

After all this setup, a task contacts the OONI bouncer, lookups the IP address,
the country code, the autonomous system number, and the resolver lookup. All
these information end up in the JSON measurement. Also, all these operations can
be explicitly disabled by setting the appropriate settings.

```JavaScript
  let test_helpers = test.defaultTestHelpers()
  if (!settings.options.no_bouncer) {
    if (settings.options.bouncer_base_url == "") {
      settings.options.bouncer_base_url = defaultBouncerBaseURL()
    }
    let error
    [test_helpers, error] = queryOONIBouncer(settings)
    if (error) {
      emitWarning(settings, "cannot query OONI bouncer")
      if (!settings.options.ignore_bouncer_error) {
        finish(error)
        return
      }
    }
  }

  // TODO(bassosimone): we should make sure the progress described here
  // is consistent with the one emitted by the real code.
  emitProgress(0.1, "contacted bouncer")

  let probe_ip = "127.0.0.1"
  if (settings.options.probe_ip != "") {
    probe_ip = settings.options.probe_ip
  } else if (!settings.options.no_ip_lookup) {
    let error
    [probe_ip, error] = lookupIP(settings)
    if (error) {
      emitEvent("failure.ip_lookup", {
        failure: error.AsString()
      })
      emitWarning(settings, "cannot lookup probe IP")
    }
  }

  let probe_asn = "AS0",
      probe_network_name = "Unknown"
  if (settings.options.probe_asn != "") {
    probe_asn = settings.options.probe_asn
  } else if (!settings.options.no_asn_lookup &&
             settings.options.geoip_asn_path != "") {
    let error
    [probe_asn, probe_network_name, error] = lookupASN(settings)
    if (error) {
      emitEvent("failure.asn_lookup", {
        failure: error.AsString()
      })
      emitWarning(settings, "cannot lookup probe ASN")
    }
  }

  let probe_cc = "ZZ"
  if (settings.options.probe_cc != "") {
    probe_cc = settings.options.probe_cc
  } else if (!settings.options.no_cc_lookup &&
             settings.options.geoip_country_path != "") {
    let error
    [probe_cc, error] = lookupCC(settings)
    if (error) {
      emitEvent("failure.cc_lookup", {
        failure: error.AsString()
      })
      emitWarning(settings, "cannot lookup probe CC")
    }
  }

  emitEvent("status.geoip_lookup", {
    probe_ip: probe_ip,
    probe_asn: probe_asn,
    probe_network_name: probe_network_name,
    probe_cc: probe_cc
  })

  emitProgress(0.2, "geoip lookup")

  // TODO(bassosimone): take decision wrt null vs. ""
  let resolver_ip = null
  if (!settings.options.no_resolver_lookup) {
    let error
    [resolver_ip, error] = lookupResolver(settings)
    if (error) {
      emitEvent("failure.resolver_lookup", {
        failure: error.AsString()
      })
      emitWarning(settings, "cannot lookup resolver IP")
    }
  }

  emitEvent("status.resolver_lookup", {
    resolver_ip: resolver_ip
  })
  emitProgress(0.3, "resolver lookup")
```

Then, Measurement Kit opens the report file on disk, which will contain
the measurements, each serialized on a JSON on its own line. It will also
contact the OONI bouncer and obtain a report-ID for the report.

```JavaScript
  if (!settings.options.no_file_report) {
    if (settings.output_filepath == "") {
      settings.output_filepath = makeDefaultOutputFilepath(settings);
    }
    let error = openFileReport(settings.output_filepath)
    if (error) {
      emitWarning(settings, "cannot open file report")
      finish(error)
      return
    }
  }

  let report_id
  if (!settings.options.no_collector) {
    if (settings.options.collector_base_url == "") {
      settings.options.collector_base_url = defaultCollectorBaseURL();
    }
    let error
    [report_id, error] = collectorOpenReport(settings)
    if (error) {
      emitWarning("cannot open report with OONI collector")
      emitEvent("failure.report_create", {
        failure: error.AsString()
      })
      if (!settings.options.ignore_open_report_error) {
        finish(error)
        return
      }
    } else {
      emitEvent("status.report_create", {
        report_id: report_id
      })
    }
  }

  emitProgress(0.4, "open report")
```

Then comes input processing. Measurement Kit assembles a list of inputs to
process. If the test do not take any input, we fake a single input entry
consisting of the empty string, implying that this test needs to perform just
a single iteration. (This is a somewhat internal detail, but it explains
some events with `idx` equal to `0` and `input` equal to an empty string.)

```JavaScript
  for (let i = 0; i < settings.input_filepaths.length; ++i) {
    let [inputs, error] = readInputFile(settings.input_filepaths[i])
    if (error) {
      emitWarning("cannot read input file")
      finish(error)
      return
    }
    settings.inputs = settings.inputs.concat(inputs)
  }
  if (settings.inputs.length <= 0) {
    if (task.needs_input) {
      emitWarning(settings, "no input provided")
      finish(Error("value_error"))
      return
    }
    settings.inputs.push("") // empty input for input-less tests
  }
  if (settings.options.randomize_input) {
    shuffle(settings.input)
  }
```

Then, Measurement Kit iterates over all the input and runs the function
implementing the specified task on each input.

```JavaScript
  let begin = timeNow()
  for (let i = 0; i < settings.inputs; ++i) {
    let currentTime = timeNow()
    if (settings.options.max_runtime >= 0 &&
        currentTime - begin > settings.options.max_runtime) {
      emitWarning("exceeded maximum runtime")
      break
    }
    emitEvent("status.measurement_start", {
      idx: i,
      input: settings.inputs[i]
    })
    let measurement = Measurement()
    measurement.annotations = settings.annotations
    measurement.annotations.engine_name = "libmeasurement_kit"
    measurement.annotations.engine_version = mkVersion()
    measurement.annotations.engine_version_full = mkVersionFull()
    measurement.annotations.platform = platformName()
    measurement.annotations.probe_network_name = settings.options.save_real_probe_asn
                                                  ? probe_network_name : "Unknown"
    measurement.id = UUID4()
    measurement.input = settings.inputs[i]
    measurement.input_hashes = []
    measurement.measurement_start_time = currentTime
    measurement.options = []
    measurement.probe_asn = settings.options.save_real_probe_asn ? probe_asn : "AS0"
    measurement.probe_cc = settings.options.save_real_probe_cc ? probe_cc : "ZZ"
    measurement.probe_ip = settings.options.save_real_probe_ip
                              ? probe_ip : "127.0.0.1"
    measurement.report_id = report_id
    measurement.sotfware_name = settings.options.software_name
    measurement.sotfware_version = settings.options.software_version
    measurement.test_helpers = test_helpers
    measurement.test_name = test.AsOONITestName()
    measurement.test_start_time = begin
    measurement.test_verson = test.Version()
    let [test_keys, error] = task.Run(
          settings.inputs[i], settings, test_helpers)
    measurement.test_runtime = timeNow() - currentTime
    measurement.test_keys = test_keys
    measurement.test_keys.resolver_ip = settings.options.save_resolver_ip
                                          ? resolve_ip : "127.0.0.1"
    if (error) {
      emitEvent("failure.measurement", {
        failure: error.AsString(),
        idx: i,
        input: settings.inputs[i]
      })
    }
    emitEvent("measurement", {
      json_str: measurement.asJSON(),
      idx: i,
      input: settings.inputs[i]
    })
    if (!settings.options.no_file_report) {
      let error = writeReportToFile(measurement)
      if (error) {
        emitWarning("cannot write report to file")
        finish(error)
        return
      }
    }
    if (!settings.options.no_collector) {
      let error = submitMeasurementToOONICollector(measurement)
      if (error) {
        emitEvent("failure.measurement_submission", {
          idx: i,
          input: settings.inputs[i],
          json_str: measurement.asJSON(),
          failure: error.AsString()
        })
      } else {
        emitEvent("status.measurement_submission", {
          idx: i,
          input: settings.inputs[i],
        })
      }
    }
    emitEvent("status.measurement_done", {
      idx: i
    })
  }
```

Finally, Measurement Kit ends the test by closing the local results file
and the remote report managed by the OONI collector.

```JavaScript
  emitProgress(0.9, "ending the test")

  if (!settings.options.no_file_report) {
    error = closeFileReport()
    if (error) {
      emitWarning("cannot close file report")
      finish(error)
      return
    }
  }
  if (!settings.options.no_collector) {
    let error = closeRemoteReport()
    if (error) {
      emitEvent("failure.report_close", {
        failure: error.AsString()
      })
      emitWarning("cannot close remote report with OONI collector")
    } else {
      emitEvent("status.report_close", {
        report_id: report_id
      })
    }
  }

  finish()
}
```
